{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f55912e4-edcc-4792-b84f-f9a39975ae61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pycountry\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, LabelBinarizer\n",
    "pd.set_option('display.max_columns', 500)\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "059736ef-2164-4596-98e8-f365110949d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luism\\anaconda3\\envs\\milestone_1\\Lib\\site-packages\\pycountry\\db.py:51: UserWarning: Country's official_name not found. Country name provided instead.\n",
      "  warnings.warn(warning_message, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ppp.csv', 'salaries.csv', 'stack_overflow']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_overflow_files = (os.listdir(\"data/\"))\n",
    "# not worth going from 2011-2014. No data scientists.\n",
    "# ok, so decision to do (2019 maybe) 2020-2023 for analysis\n",
    "\n",
    "# GPT gave me this idea instead of going through every possible country manually\n",
    "country_abbreviations_1 = {country.name: country.alpha_3 for country in pycountry.countries}\n",
    "country_abbreviations_2 = {country.official_name: country.alpha_3 for country in pycountry.countries}\n",
    "os.listdir(\"data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c841912-a2ba-4055-84b6-44b79d4064a5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc27672e-a483-4135-bec9-523576a512ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_onehot_skills(frames: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Given a dictionary of pandas dataframes we want to one hot the skills in particular.\n",
    "    We want to take the skills in the different columns and one hot them such we can sum them for groupby operations.\n",
    "    We get a dictionary of pandas DataFrames and perform an inplace operation such that we don't have to create new memory.\n",
    "    Return a dictionary of a list of strings for a couple reasons:\n",
    "        - there's no way we will remember all of these so automation by putting these into a list seemed like the best idea\n",
    "        - the keys will match those in the input in case we want to do something with these later per year\n",
    "        - hashing onto a dictionary should allow for ease of access since no 2 years will have the same EXACT one hot columns, hence the list\n",
    "\n",
    "    We also drop the _Empty for EVERYTHING since that information is useless to us\n",
    "    \n",
    "    Input: frames dict{str: pd.DataFrames}\n",
    "    Ouput: dict{str: list[str]}\n",
    "\n",
    "    https://stackoverflow.com/questions/45312377/how-to-one-hot-encode-from-a-pandas-column-containing-a-list\n",
    "\n",
    "    Rough example flow of function for one sample:\n",
    "    C; C++; Perl -> [C, C++, Perl] -> [1, 1, 1, 0]\n",
    "    Python       -> [Python]       -> [0, 0, 0, 1]\n",
    "    \"\"\"\n",
    "    # some constants\n",
    "    standard = [(\"language\", \"lg\"), (\"database\", \"db\"), (\"platform\", \"pf\"), (\"webframe\", \"wf\"), (\"misctech\", \"mt\")]\n",
    "    status = [(\"wanttoworkwith\", \"www\"), (\"haveworkedwith\", \"hww\")]\n",
    "\n",
    "    new_cols_per_year = {}\n",
    "    \n",
    "    for key, frame in frames.items():\n",
    "        new_cols = []\n",
    "        for stan, abv in standard:\n",
    "            for stat, abr in status:\n",
    "                coi = stan + stat # coi = column of interest\n",
    "                abbr = abv + abr + \"_\"\n",
    "                mlb = MultiLabelBinarizer(sparse_output=True) # saves ram\n",
    "                frame[coi] = frame[coi].str.split(\";\")\n",
    "                transformed = mlb.fit_transform(frame.pop(coi))\n",
    "                new_cois = [abbr + name for name in mlb.classes_]\n",
    "                frame = frame.join(\n",
    "                            pd.DataFrame.sparse.from_spmatrix(\n",
    "                                transformed,\n",
    "                                index=frame.index,\n",
    "                                columns=new_cois\n",
    "                            )\n",
    "                        )\n",
    "                new_cois.remove(abbr + \"Empty\")\n",
    "                new_cols += new_cois\n",
    "                frame = frame.drop(abbr + \"Empty\", axis=1)\n",
    "        # this needs to be here, if not throse Sparse type errors\n",
    "        # # Sparse types don't allow normal groupby operations (ie reshape) so we need to turn them into ints\n",
    "        # # int8 don't take up a ton and it's just 0's and 1's\n",
    "        # # for all intents and purposes these are sparse matrices, we just want to avoid the object\n",
    "        frame[new_cols] = frame[new_cols].fillna(0)\n",
    "        frame[new_cols] = frame[new_cols].astype('int8')\n",
    "        frames[key] = frame\n",
    "        new_cols_per_year[key] = new_cols\n",
    "    return new_cols_per_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c497e6d-c221-4d15-92c1-d1af1334b646",
   "metadata": {},
   "outputs": [],
   "source": [
    "def abbr_education(frames: dict) -> None:\n",
    "    \"\"\"\n",
    "    Similar in spirit to the other one hots, but this is in place\n",
    "    Automatically abbreviates education levels across all frames\n",
    "    Had to hard code the list again, not a big deal only 8 items\n",
    "    \n",
    "    Input: frames dict{str: pd.DataFrames}\n",
    "    Ouput: None\n",
    "    \"\"\"\n",
    "    # more hardcoded stuff that are needed\n",
    "    abbreviations = [\"ad\", \"bs\", \"ms\", \"ele\", \"prof\", \"sec\", \"scu\", \"else\"]\n",
    "    \n",
    "    for key, frame in frames.items():\n",
    "        # easier to replace this, makes it much easier to work with\n",
    "        frame['edlevel'] = frame['edlevel'].replace({'I never completed any formal education': 'Something else'})\n",
    "\n",
    "        # need the sorted since they have the same rough scheme\n",
    "        levels = list(frame['edlevel'].unique())\n",
    "        levels.sort()\n",
    "        o = 0 # offset\n",
    "\n",
    "        # dictionary to feed into repalce function\n",
    "        replace_dict = {}\n",
    "        for i in range(len(levels)):\n",
    "            col = levels[i]\n",
    "            if col == 'nan':\n",
    "                break\n",
    "            abbr = abbreviations[i-o]\n",
    "            if 'doctoral' in col:\n",
    "                replace_dict[col] = \"phd\"\n",
    "                o += 1\n",
    "                continue\n",
    "            replace_dict[col] = abbr\n",
    "                \n",
    "        frame['edlevel'] = frame['edlevel'].replace(replace_dict)\n",
    "        frames[key] = frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54ea221e-f02a-409e-b2aa-c6af9ac41cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_onehot_edu(frames: dict) -> None:\n",
    "    \"\"\"\n",
    "    Inplace one hotting of frames dictionary for edulevel column.\n",
    "    We are dropping nan's again since we aren't able to guess an education level.\n",
    "    They don't give us any information and would only be an obstacle in analysis.\n",
    "    \n",
    "    Input: frames dict{str: pd.DataFrame}\n",
    "    Output: None\n",
    "    \"\"\"\n",
    "    # inplace\n",
    "    abbr_education(frames)\n",
    "\n",
    "    # go through our frames\n",
    "    for key, frame in frames.items():\n",
    "        # mlb doesn't work since it will use char, and we want str\n",
    "        lb = LabelBinarizer(sparse_output=True) # saves ram\n",
    "        transformed = lb.fit_transform(frame.pop('edlevel'))\n",
    "        frame = frame.join(\n",
    "                    pd.DataFrame.sparse.from_spmatrix(\n",
    "                        transformed,\n",
    "                        index=frame.index,\n",
    "                        columns=lb.classes_\n",
    "                    )\n",
    "                )\n",
    "        new_cols = list(lb.classes_)\n",
    "\n",
    "        # edge case so all columns line up\n",
    "        if 'phd' not in frame.columns:\n",
    "            frame['phd'] = [0] * len(frame)\n",
    "            new_cols.append('phd')\n",
    "        \n",
    "        # tells us nothing\n",
    "        if 'nan' in frame.columns:\n",
    "            frame = frame.drop('nan', axis=1)\n",
    "            new_cols.remove('nan')\n",
    "        frame[new_cols] = frame[new_cols].fillna(0)\n",
    "        frame[new_cols] = frame[new_cols].astype('int8')\n",
    "        frames[key] = frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10e6e980-8b30-4feb-872e-64cceaa62a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_stackoverflow() -> (dict, dict):\n",
    "    \"\"\"\n",
    "    Reads CSVs and gets the numbe of data professionals. Any empty values are dropped from job title and \n",
    "    salary so we will always have data. Other columns may have nans.\n",
    "    Data Manipulation:\n",
    "    - dropping nans from salary and devtype combined\n",
    "    - Changing the salary column to ConvertedCompYearly so we can merge all data frames comes time\n",
    "    - Lowering column names since there was some weird camel case going on\n",
    "    - Converting specific columns that mean the same thing per year into a singular name\n",
    "    - Fill in nans for language/skill specific values with \"Empty\"\n",
    "      - this is so we can one hot later on for a more concise analysis, more later on\n",
    "    - One hot encoding the different skills per year, see create_onehot_skills\n",
    "    - Next we abbreviate education levels so that we can also one hot them, see above\n",
    "    - One hot education, see other documentation\n",
    "\n",
    "    Inputs: Nothing\n",
    "    Outputs: tuple(dict{str: pd.DataFrame}, dict{str: list[str]})\n",
    "    \"\"\"\n",
    "    frames = {}\n",
    "    stack_o_files = os.listdir(\"data/stack_overflow/\")\n",
    "    for file in stack_o_files:\n",
    "        year = file[-8:-4]\n",
    "        df = pd.read_csv(f\"data/stack_overflow/{file}\", encoding='ISO-8859-1')\n",
    "\n",
    "        # standardize compensation columns\n",
    "        if 'ConvertedComp' in df.columns:\n",
    "            df = df.rename(columns={'ConvertedComp': 'ConvertedCompYearly'})\n",
    "\n",
    "        # standardize some columns\n",
    "        # using camel case resulted in errors with webframe where sometimes F was capitalized\n",
    "        standard = [\"language\", \"database\", \"platform\", \"webframe\", \"misctech\"]\n",
    "        df.columns = df.columns.str.lower()\n",
    "        for stan in standard:\n",
    "            if f\"{stan}workedwith\" in df.columns:\n",
    "                df = df.rename(columns={f'{stan}workedwith': f'{stan}haveworkedwith', f'{stan}desirenextyear':f'{stan}wanttoworkwith'})\n",
    "            df[f\"{stan}haveworkedwith\"] = df[f\"{stan}haveworkedwith\"].fillna(value=\"Empty\")\n",
    "            df[f\"{stan}wanttoworkwith\"] = df[f\"{stan}wanttoworkwith\"].fillna(value=\"Empty\")\n",
    "\n",
    "        # standardize some country names, now they should match with Kaggle dataset\n",
    "        df[\"country\"] = df[\"country\"].replace(country_abbreviations_1)\n",
    "        df[\"country\"] = df[\"country\"].replace(country_abbreviations_2)\n",
    "\n",
    "        df['edlevel'] = df['edlevel'].fillna(value=\"nan\")\n",
    "        \n",
    "        df = df.dropna(subset=[\"devtype\", \"convertedcompyearly\"])\n",
    "        df = df[df[\"devtype\"].str.contains(\"data\", case=False)]\n",
    "        df[\"count\"] = [1] * len(df) # this is for our groupby so that we can say count > cull when we sum or count\n",
    "        df[\"year\"] = [year] * len(df)\n",
    "        frames[f\"df_data_{year}\"] = df\n",
    "\n",
    "    # oops forgot indentation\n",
    "    create_onehot_edu(frames)\n",
    "    new_cols = create_onehot_skills(frames)\n",
    "    return frames, new_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a8097b-2f9c-4802-952c-0bfeecd6fdfe",
   "metadata": {},
   "source": [
    "## The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79449a31-8bd9-4b64-b93f-0deedb21f33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_dict, new_cols = read_stackoverflow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35d213b7-8f49-44c3-8789-2fc652b539ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = frames_dict[\"df_data_2019\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1755cb56-6785-4ade-8ef7-3fcf15945bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.dtypes[df. dtypes == 'Sparse[int32, 0]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a5074c0-27cd-45da-a180-c5c5ed5aad54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(frames_dict[\"df_data_2019\"].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44403370-fb7b-4679-ac9b-856cf16b4db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_data_2019\t13393\t['lgwww_WebAssembly', 'lghww_WebAssembly']\n",
      "df_data_2020\t8294\t[]\n",
      "df_data_2021\t9272\t[]\n",
      "df_data_2022\t6921\t[]\n",
      "df_data_2023\t2480\t['pfwww_Amazon Web Services (AWS)', 'pfhww_Amazon Web Services (AWS)']\n"
     ]
    }
   ],
   "source": [
    "# this is the number of entries we are working with in our frames\n",
    "# seeing how to standardize the columns some more\n",
    "# this is kind of useless now with one hotting everything\n",
    "\n",
    "query = \"Web\"\n",
    "for key, frame in frames_dict.items():\n",
    "    lang = []\n",
    "    for col in frame.columns:\n",
    "        lang.append(col) if query in col else None\n",
    "    print(f\"{key}\\t{len(frame)}\\t{lang}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8b6973f-16be-4d0e-a9a2-543078294b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(frames_dict[\"df_data_2019\"].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89e54b52-86b0-4468-a526-33b7dabc5db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(frames_dict[\"df_data_2020\"].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5382c8f8-589e-4817-8762-56ae2368768c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(frames_dict[\"df_data_2021\"].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e954c060-4e0c-47b6-b32f-fd206ad8ab9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(frames_dict[\"df_data_2022\"].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47802c31-8420-41b5-8c3b-870494d64683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(frames_dict[\"df_data_2023\"].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee23bc3-c2b2-4501-9380-8d23af324b80",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Similarity with columns per the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "273a278b-e4c9-4ee9-8ad2-588f9757d841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do they have similar columns?\n",
    "def find_similar_col(frames) -> set:\n",
    "    \"\"\"\n",
    "    Returns the set of columns that the all share, ideally we maximize the ratio of this to merge.\n",
    "    \"\"\"\n",
    "    union = []\n",
    "    for key, frame in frames.items():\n",
    "        union.append(set(frame.columns))\n",
    "        \n",
    "    standard = union[0]\n",
    "    for cols in union[1:]:\n",
    "        standard = standard.intersection(cols)\n",
    "    return standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73d86b23-42fa-47a5-95cb-e1c00f86f9b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ad',\n",
       " 'age',\n",
       " 'bs',\n",
       " 'comptotal',\n",
       " 'convertedcompyearly',\n",
       " 'count',\n",
       " 'country',\n",
       " 'dbhww_Cassandra',\n",
       " 'dbhww_Couchbase',\n",
       " 'dbhww_Elasticsearch',\n",
       " 'dbhww_MariaDB',\n",
       " 'dbhww_Microsoft SQL Server',\n",
       " 'dbhww_MongoDB',\n",
       " 'dbhww_MySQL',\n",
       " 'dbhww_Oracle',\n",
       " 'dbhww_PostgreSQL',\n",
       " 'dbhww_Redis',\n",
       " 'dbhww_SQLite',\n",
       " 'dbwww_Cassandra',\n",
       " 'dbwww_Couchbase',\n",
       " 'dbwww_Elasticsearch',\n",
       " 'dbwww_MariaDB',\n",
       " 'dbwww_Microsoft SQL Server',\n",
       " 'dbwww_MongoDB',\n",
       " 'dbwww_MySQL',\n",
       " 'dbwww_Oracle',\n",
       " 'dbwww_PostgreSQL',\n",
       " 'dbwww_Redis',\n",
       " 'dbwww_SQLite',\n",
       " 'devtype',\n",
       " 'ele',\n",
       " 'else',\n",
       " 'employment',\n",
       " 'lghww_Assembly',\n",
       " 'lghww_C',\n",
       " 'lghww_C#',\n",
       " 'lghww_C++',\n",
       " 'lghww_Dart',\n",
       " 'lghww_Go',\n",
       " 'lghww_HTML/CSS',\n",
       " 'lghww_Java',\n",
       " 'lghww_JavaScript',\n",
       " 'lghww_Kotlin',\n",
       " 'lghww_Objective-C',\n",
       " 'lghww_PHP',\n",
       " 'lghww_Python',\n",
       " 'lghww_R',\n",
       " 'lghww_Ruby',\n",
       " 'lghww_Rust',\n",
       " 'lghww_SQL',\n",
       " 'lghww_Scala',\n",
       " 'lghww_Swift',\n",
       " 'lghww_TypeScript',\n",
       " 'lghww_VBA',\n",
       " 'lgwww_Assembly',\n",
       " 'lgwww_C',\n",
       " 'lgwww_C#',\n",
       " 'lgwww_C++',\n",
       " 'lgwww_Dart',\n",
       " 'lgwww_Go',\n",
       " 'lgwww_HTML/CSS',\n",
       " 'lgwww_Java',\n",
       " 'lgwww_JavaScript',\n",
       " 'lgwww_Kotlin',\n",
       " 'lgwww_Objective-C',\n",
       " 'lgwww_PHP',\n",
       " 'lgwww_Python',\n",
       " 'lgwww_R',\n",
       " 'lgwww_Ruby',\n",
       " 'lgwww_Rust',\n",
       " 'lgwww_SQL',\n",
       " 'lgwww_Scala',\n",
       " 'lgwww_Swift',\n",
       " 'lgwww_TypeScript',\n",
       " 'lgwww_VBA',\n",
       " 'mainbranch',\n",
       " 'ms',\n",
       " 'mthww_Apache Spark',\n",
       " 'mthww_Cordova',\n",
       " 'mthww_Flutter',\n",
       " 'mthww_Hadoop',\n",
       " 'mthww_Pandas',\n",
       " 'mthww_React Native',\n",
       " 'mthww_TensorFlow',\n",
       " 'mthww_Torch/PyTorch',\n",
       " 'mtwww_Apache Spark',\n",
       " 'mtwww_Cordova',\n",
       " 'mtwww_Flutter',\n",
       " 'mtwww_Hadoop',\n",
       " 'mtwww_Pandas',\n",
       " 'mtwww_React Native',\n",
       " 'mtwww_TensorFlow',\n",
       " 'mtwww_Torch/PyTorch',\n",
       " 'orgsize',\n",
       " 'pfhww_Heroku',\n",
       " 'pfhww_Microsoft Azure',\n",
       " 'pfwww_Heroku',\n",
       " 'pfwww_Microsoft Azure',\n",
       " 'phd',\n",
       " 'prof',\n",
       " 'scu',\n",
       " 'sec',\n",
       " 'soaccount',\n",
       " 'socomm',\n",
       " 'sopartfreq',\n",
       " 'sovisitfreq',\n",
       " 'surveyease',\n",
       " 'surveylength',\n",
       " 'wfhww_ASP.NET',\n",
       " 'wfhww_Django',\n",
       " 'wfhww_Drupal',\n",
       " 'wfhww_Express',\n",
       " 'wfhww_Flask',\n",
       " 'wfhww_Laravel',\n",
       " 'wfhww_Ruby on Rails',\n",
       " 'wfhww_Vue.js',\n",
       " 'wfhww_jQuery',\n",
       " 'wfwww_ASP.NET',\n",
       " 'wfwww_Django',\n",
       " 'wfwww_Drupal',\n",
       " 'wfwww_Express',\n",
       " 'wfwww_Flask',\n",
       " 'wfwww_Laravel',\n",
       " 'wfwww_Ruby on Rails',\n",
       " 'wfwww_Vue.js',\n",
       " 'wfwww_jQuery',\n",
       " 'year',\n",
       " 'yearscode',\n",
       " 'yearscodepro'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_similar_col(frames_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8becc9-1c9c-4db7-ad19-aa5db3614321",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Countries given a cull factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "add4430f-be36-47eb-aed9-ff0b9a619e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_data_2019\n",
      "df_data_2019: 83\n",
      "    max: USA, 3856\n",
      "    min: ARM, 11\n",
      "df_data_2020\n",
      "df_data_2020: 69\n",
      "    max: USA, 2081\n",
      "    min: BLR, 11\n",
      "df_data_2021\n",
      "df_data_2021: 70\n",
      "    max: USA, 2144\n",
      "    min: BIH, 11\n",
      "df_data_2022\n",
      "df_data_2022: 63\n",
      "    max: USA, 1702\n",
      "    min: EGY, 11\n",
      "df_data_2023\n",
      "df_data_2023: 36\n",
      "    max: USA, 687\n",
      "    min: CHN, 11\n"
     ]
    }
   ],
   "source": [
    "# play around with the number and see if this is the spread that we want\n",
    "for key, frame in frames_dict.items():\n",
    "    print(key)\n",
    "    grouped = frame.groupby(\"country\").count()\n",
    "    grouped = grouped[grouped[\"mainbranch\"] > 10]\n",
    "    length = len(grouped)\n",
    "    print(f\"\"\"{key}: {length}\n",
    "    max: {grouped['mainbranch'].idxmax()}, {grouped['mainbranch'].max()}\n",
    "    min: {grouped['mainbranch'].idxmin()}, {grouped['mainbranch'].min()}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c637099f-3869-4d84-97c5-89ddcc9bd3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do they have similar columns?\n",
    "def find_similar_country(frames: dict, cull_factor=20) -> set:\n",
    "    \"\"\"\n",
    "    Given a particular minimum (cull_factor) find the countries in common among\n",
    "    frames.\n",
    "    \"\"\"\n",
    "    union = []\n",
    "    for key, frame in frames.items():\n",
    "        grouped = frame.groupby(\"country\").count()\n",
    "        grouped = grouped[grouped[\"mainbranch\"] > cull_factor]\n",
    "        union.append(set(grouped.index))\n",
    "        \n",
    "    standard = union[0]\n",
    "    for cols in union[1:]:\n",
    "        standard = standard.intersection(cols)\n",
    "    return standard\n",
    "\n",
    "def show_country_dist(frames: dict, countries: list, cull_factor: int) -> None:\n",
    "    \"\"\"\n",
    "    Just plot a bar chart for our country distributions using the above function.\n",
    "    \"\"\"\n",
    "    rows = len(frames)//2 + 1\n",
    "    fig, axes = plt.subplots(nrows=rows, ncols=2, figsize=(15,15))\n",
    "    fig.suptitle(f\"{len(countries)} respondents consistent across surveys greater than {cull_factor} responses\")\n",
    "    for (key, frame), ax in zip(frames.items(), axes.reshape(-1)):\n",
    "        grouped = frame.groupby(\"country\").count()\n",
    "        grouped = grouped.loc[list(countries)].sort_values(\"mainbranch\")\n",
    "        grouped.plot(y=\"mainbranch\", ax=ax, kind=\"bar\", legend=False)\n",
    "        ax.set_title(key[-4:])\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b1e1d0c-5b5d-4f78-a0aa-460668f729f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# across all data sets here are the countries that are here most often\n",
    "# where is US? UK? They have different, inconsistent names throughout the years\n",
    "# # i.e. United States vs United States of America; UK vs United Kingdom, see above mapping\n",
    "cull_factor = 20\n",
    "country_sim = find_similar_country(frames_dict, cull_factor)\n",
    "# show_country_dist(frames_dict, list(country_sim), cull_factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005703d4-1baf-4f62-80a1-7d0fb67882bd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## One Hot Testing for Skills (deprecated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1b308f2b-2eeb-4ac0-aeaf-6711431064f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basically with every one of these is separated by a ;\n",
    "# goal of next function:\n",
    "# # find the sub-strings separated by ; nans will have to be replaced by \"None\" or \"Empty\"\n",
    "# # one hot the entries for example, if C appears in one of these queries, for that particular\n",
    "# # subject there will be a 1 for yes and 0 for no essentially\n",
    "# # this is why we need the None/Empty so we can add them up\n",
    "# # Eventually after one hotting we drop the None/Empty since it's a dummy column\n",
    "# # we would then be able to add them up using count or something and put onto a graph/analysis\n",
    "\n",
    "\n",
    "# standard = [\"language\", \"database\", \"platform\", \"webframe\", \"misctech\"]\n",
    "# want = \"wanttoworkwith\"\n",
    "# have = \"haveworkedwith\"\n",
    "# for key, frame in frames_dict.items():\n",
    "#     print(key)\n",
    "#     for stan in standard:\n",
    "#         print(f\"{stan}: {frame[stan + want].isna().sum()} {frame[stan + want].sample(n=1).values}\")\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ddc1150b-2867-4d8f-aaa6-552cd78e92ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = frames_dict[\"df_data_2019\"].copy(deep=True) # don't want this to point at the frame in dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5204937d-79cd-43c9-9638-1f86471d7843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coi = 'languagewanttoworkwith'\n",
    "# df[coi] = df[coi].str.split(\";\")\n",
    "# mlb = MultiLabelBinarizer(sparse_output=True) # saves ram\n",
    "\n",
    "# transformed = mlb.fit_transform(df.pop(coi))\n",
    "# columns = [\"langwork_\" + name for name in mlb.classes_]\n",
    "\n",
    "# df = df.join(\n",
    "#             pd.DataFrame.sparse.from_spmatrix(\n",
    "#                 transformed,\n",
    "#                 index=df.index,\n",
    "#                 columns=columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "008b8f84-0576-4a88-9034-f836aa3b2034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# frame = frames_dict[\"df_data_2019\"].copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "652a6427-f65e-49e5-a73e-57c91a53e40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.groupby('country').sum()[mlb.classes_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fef1474d-4069-4df1-b543-86c0d1cb275e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_onehot_skills(frames: dict):\n",
    "#     # some constants\n",
    "#     standard = [(\"language\", \"lg\"), (\"database\", \"db\"), (\"platform\", \"pf\"), (\"webframe\", \"wf\"), (\"misctech\", \"mt\")]\n",
    "#     status = [(\"wanttoworkwith\", \"www\"), (\"haveworkedwith\", \"hww\")]\n",
    "\n",
    "#     new_cols_per_year = {}\n",
    "    \n",
    "#     for key, frame in frames.items():\n",
    "#         new_cols = []\n",
    "#         print(key)\n",
    "#         for stan, abv in standard:\n",
    "#             for stat, abr in status:\n",
    "#                 coi = stan + stat # coi = column of interest\n",
    "#                 abbr = abv + abr + \"_\"\n",
    "#                 mlb = MultiLabelBinarizer(sparse_output=True) # saves ram\n",
    "#                 frame[coi] = frame[coi].str.split(\";\")\n",
    "#                 transformed = mlb.fit_transform(frame.pop(coi))\n",
    "#                 new_cois = [abbr + name for name in mlb.classes_]\n",
    "#                 frame = frame.join(\n",
    "#                             pd.DataFrame.sparse.from_spmatrix(\n",
    "#                                 transformed,\n",
    "#                                 index=frame.index,\n",
    "#                                 columns=new_cois\n",
    "#                             )\n",
    "#                         )\n",
    "#                 new_cois.remove(abbr + \"Empty\")\n",
    "#                 new_cols += new_cois\n",
    "#                 frame.drop(abbr + \"Empty\", axis=1)\n",
    "#         frames[key] = frame\n",
    "#         new_cols_per_year[key] = new_cols\n",
    "#     return new_cols_per_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ab559801-d6f4-463e-ab28-2080804e2f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import copy\n",
    "# cp_dict = copy.deepcopy(frames_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5d402790-a9e9-46fa-b52e-52fea6080c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_cols = create_onehot_skills(cp_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36f2011-b9ce-4338-a00f-102d9bea271c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Ed Level Processing (deprecated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "29ab9aee-18d7-4fea-9306-949f9c8ce38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot education for same reason\n",
    "# same thing\n",
    "# we have nans and doctoral degrees missing from 2023 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9c21f6c8-82d2-421e-a4fc-11f4640815a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import copy\n",
    "# cp_dict = copy.deepcopy(frames_dict)\n",
    "# abbr_education(cp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "54f497be-d0d8-4eb8-9dce-b5167ddc381b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key, frame in cp_dict.items():\n",
    "#     frame['edlevel'] = frame['edlevel'].replace({'I never completed any formal education': 'Something else'})\n",
    "    \n",
    "#     do = list(frame['edlevel'].unique())\n",
    "#     print(key, len(do))\n",
    "#     do.sort()\n",
    "#     display(do)\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0bc839d2-8939-447a-b7e7-1338b474e11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key, frame in cp_dict.items():\n",
    "#     lb = LabelBinarizer(sparse_output=True) # saves ram\n",
    "#     transformed = lb.fit_transform(frame.pop('edlevel'))\n",
    "#     frame = frame.join(\n",
    "#                 pd.DataFrame.sparse.from_spmatrix(\n",
    "#                     transformed,\n",
    "#                     index=frame.index,\n",
    "#                     columns=lb.classes_\n",
    "#                 )\n",
    "#             )\n",
    "#     if 'phd' not in frame.columns:\n",
    "#         frame['phd'] = [0] * len(frame)\n",
    "#     print(frame.columns[-10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd785f8-d94f-4bf3-9374-bf9f8398f887",
   "metadata": {},
   "source": [
    "## Employment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e45a7b1b-822f-40d1-982e-9f97d9b3294f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ad',\n",
       " 'age',\n",
       " 'bs',\n",
       " 'comptotal',\n",
       " 'convertedcompyearly',\n",
       " 'count',\n",
       " 'country',\n",
       " 'dbhww_Cassandra',\n",
       " 'dbhww_Couchbase',\n",
       " 'dbhww_Elasticsearch',\n",
       " 'dbhww_MariaDB',\n",
       " 'dbhww_Microsoft SQL Server',\n",
       " 'dbhww_MongoDB',\n",
       " 'dbhww_MySQL',\n",
       " 'dbhww_Oracle',\n",
       " 'dbhww_PostgreSQL',\n",
       " 'dbhww_Redis',\n",
       " 'dbhww_SQLite',\n",
       " 'dbwww_Cassandra',\n",
       " 'dbwww_Couchbase',\n",
       " 'dbwww_Elasticsearch',\n",
       " 'dbwww_MariaDB',\n",
       " 'dbwww_Microsoft SQL Server',\n",
       " 'dbwww_MongoDB',\n",
       " 'dbwww_MySQL',\n",
       " 'dbwww_Oracle',\n",
       " 'dbwww_PostgreSQL',\n",
       " 'dbwww_Redis',\n",
       " 'dbwww_SQLite',\n",
       " 'devtype',\n",
       " 'ele',\n",
       " 'else',\n",
       " 'employment',\n",
       " 'lghww_Assembly',\n",
       " 'lghww_C',\n",
       " 'lghww_C#',\n",
       " 'lghww_C++',\n",
       " 'lghww_Dart',\n",
       " 'lghww_Go',\n",
       " 'lghww_HTML/CSS',\n",
       " 'lghww_Java',\n",
       " 'lghww_JavaScript',\n",
       " 'lghww_Kotlin',\n",
       " 'lghww_Objective-C',\n",
       " 'lghww_PHP',\n",
       " 'lghww_Python',\n",
       " 'lghww_R',\n",
       " 'lghww_Ruby',\n",
       " 'lghww_Rust',\n",
       " 'lghww_SQL',\n",
       " 'lghww_Scala',\n",
       " 'lghww_Swift',\n",
       " 'lghww_TypeScript',\n",
       " 'lghww_VBA',\n",
       " 'lgwww_Assembly',\n",
       " 'lgwww_C',\n",
       " 'lgwww_C#',\n",
       " 'lgwww_C++',\n",
       " 'lgwww_Dart',\n",
       " 'lgwww_Go',\n",
       " 'lgwww_HTML/CSS',\n",
       " 'lgwww_Java',\n",
       " 'lgwww_JavaScript',\n",
       " 'lgwww_Kotlin',\n",
       " 'lgwww_Objective-C',\n",
       " 'lgwww_PHP',\n",
       " 'lgwww_Python',\n",
       " 'lgwww_R',\n",
       " 'lgwww_Ruby',\n",
       " 'lgwww_Rust',\n",
       " 'lgwww_SQL',\n",
       " 'lgwww_Scala',\n",
       " 'lgwww_Swift',\n",
       " 'lgwww_TypeScript',\n",
       " 'lgwww_VBA',\n",
       " 'mainbranch',\n",
       " 'ms',\n",
       " 'mthww_Apache Spark',\n",
       " 'mthww_Cordova',\n",
       " 'mthww_Flutter',\n",
       " 'mthww_Hadoop',\n",
       " 'mthww_Pandas',\n",
       " 'mthww_React Native',\n",
       " 'mthww_TensorFlow',\n",
       " 'mthww_Torch/PyTorch',\n",
       " 'mtwww_Apache Spark',\n",
       " 'mtwww_Cordova',\n",
       " 'mtwww_Flutter',\n",
       " 'mtwww_Hadoop',\n",
       " 'mtwww_Pandas',\n",
       " 'mtwww_React Native',\n",
       " 'mtwww_TensorFlow',\n",
       " 'mtwww_Torch/PyTorch',\n",
       " 'orgsize',\n",
       " 'pfhww_Heroku',\n",
       " 'pfhww_Microsoft Azure',\n",
       " 'pfwww_Heroku',\n",
       " 'pfwww_Microsoft Azure',\n",
       " 'phd',\n",
       " 'prof',\n",
       " 'scu',\n",
       " 'sec',\n",
       " 'soaccount',\n",
       " 'socomm',\n",
       " 'sopartfreq',\n",
       " 'sovisitfreq',\n",
       " 'surveyease',\n",
       " 'surveylength',\n",
       " 'wfhww_ASP.NET',\n",
       " 'wfhww_Django',\n",
       " 'wfhww_Drupal',\n",
       " 'wfhww_Express',\n",
       " 'wfhww_Flask',\n",
       " 'wfhww_Laravel',\n",
       " 'wfhww_Ruby on Rails',\n",
       " 'wfhww_Vue.js',\n",
       " 'wfhww_jQuery',\n",
       " 'wfwww_ASP.NET',\n",
       " 'wfwww_Django',\n",
       " 'wfwww_Drupal',\n",
       " 'wfwww_Express',\n",
       " 'wfwww_Flask',\n",
       " 'wfwww_Laravel',\n",
       " 'wfwww_Ruby on Rails',\n",
       " 'wfwww_Vue.js',\n",
       " 'wfwww_jQuery',\n",
       " 'year',\n",
       " 'yearscode',\n",
       " 'yearscodepro'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_similar_col(frames_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e299b391-7367-43c6-9bfb-1ac0e2da69c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['500 to 999 employees'\n",
      " 'Just me - I am a freelancer, sole proprietor, etc.'\n",
      " '100 to 499 employees' '1,000 to 4,999 employees' '10 to 19 employees'\n",
      " '2 to 9 employees' '20 to 99 employees' 'I don√¢\\x80\\x99t know'\n",
      " '10,000 or more employees' '5,000 to 9,999 employees']\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "year = 2023\n",
    "col = \"orgsize\"\n",
    "print(frames_dict[f\"df_data_{year}\"][col].unique())\n",
    "print(frames_dict[f\"df_data_{year}\"][col].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "780df47f-f1af-42c5-8a0d-64ed0d71ab10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(list(frames_dict[\"df_data_2023\"].columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "39b48b42-21fb-4307-8cb3-0cb7eef80566",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = frames_dict[\"df_data_2023\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6963dc0a-3ee6-4f94-af9d-5e3a717b8dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df.groupby('country').agg({\"count\":[\"sum\"], \"convertedcompyearly\":[\"mean\", \"std\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3e84c190-c6e0-445b-b6eb-80741dcd549a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex([(              'count',  'sum'),\n",
       "            ('convertedcompyearly', 'mean'),\n",
       "            ('convertedcompyearly',  'std')],\n",
       "           )"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c9696c46-295c-4aac-b128-62dd5448e5fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th colspan=\"2\" halign=\"left\">convertedcompyearly</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>sum</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AUS</th>\n",
       "      <td>76</td>\n",
       "      <td>93834.868421</td>\n",
       "      <td>50171.824672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUT</th>\n",
       "      <td>25</td>\n",
       "      <td>119040.720000</td>\n",
       "      <td>199982.206651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BEL</th>\n",
       "      <td>36</td>\n",
       "      <td>79305.388889</td>\n",
       "      <td>35446.929717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BRA</th>\n",
       "      <td>72</td>\n",
       "      <td>58933.819444</td>\n",
       "      <td>201131.648916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAN</th>\n",
       "      <td>87</td>\n",
       "      <td>108793.034483</td>\n",
       "      <td>127513.909569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHE</th>\n",
       "      <td>28</td>\n",
       "      <td>140053.464286</td>\n",
       "      <td>60025.678845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEU</th>\n",
       "      <td>185</td>\n",
       "      <td>89562.378378</td>\n",
       "      <td>47131.465787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DNK</th>\n",
       "      <td>34</td>\n",
       "      <td>101817.705882</td>\n",
       "      <td>44357.573418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ESP</th>\n",
       "      <td>76</td>\n",
       "      <td>59160.315789</td>\n",
       "      <td>48200.329645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FIN</th>\n",
       "      <td>22</td>\n",
       "      <td>74806.045455</td>\n",
       "      <td>19511.362632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FRA</th>\n",
       "      <td>107</td>\n",
       "      <td>65571.000000</td>\n",
       "      <td>30233.700918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBR</th>\n",
       "      <td>206</td>\n",
       "      <td>87087.703883</td>\n",
       "      <td>49364.479534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IND</th>\n",
       "      <td>95</td>\n",
       "      <td>27374.663158</td>\n",
       "      <td>21624.291013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISR</th>\n",
       "      <td>28</td>\n",
       "      <td>128074.535714</td>\n",
       "      <td>41777.512216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ITA</th>\n",
       "      <td>49</td>\n",
       "      <td>47969.571429</td>\n",
       "      <td>23082.326163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NLD</th>\n",
       "      <td>72</td>\n",
       "      <td>89339.402778</td>\n",
       "      <td>47763.828288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NZL</th>\n",
       "      <td>21</td>\n",
       "      <td>86196.952381</td>\n",
       "      <td>35795.098087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POL</th>\n",
       "      <td>60</td>\n",
       "      <td>64081.483333</td>\n",
       "      <td>42061.947198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRT</th>\n",
       "      <td>21</td>\n",
       "      <td>49248.666667</td>\n",
       "      <td>32333.119047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SWE</th>\n",
       "      <td>35</td>\n",
       "      <td>102438.971429</td>\n",
       "      <td>163351.435846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USA</th>\n",
       "      <td>687</td>\n",
       "      <td>179245.924309</td>\n",
       "      <td>357064.100561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count convertedcompyearly               \n",
       "          sum                mean            std\n",
       "country                                         \n",
       "AUS        76        93834.868421   50171.824672\n",
       "AUT        25       119040.720000  199982.206651\n",
       "BEL        36        79305.388889   35446.929717\n",
       "BRA        72        58933.819444  201131.648916\n",
       "CAN        87       108793.034483  127513.909569\n",
       "CHE        28       140053.464286   60025.678845\n",
       "DEU       185        89562.378378   47131.465787\n",
       "DNK        34       101817.705882   44357.573418\n",
       "ESP        76        59160.315789   48200.329645\n",
       "FIN        22        74806.045455   19511.362632\n",
       "FRA       107        65571.000000   30233.700918\n",
       "GBR       206        87087.703883   49364.479534\n",
       "IND        95        27374.663158   21624.291013\n",
       "ISR        28       128074.535714   41777.512216\n",
       "ITA        49        47969.571429   23082.326163\n",
       "NLD        72        89339.402778   47763.828288\n",
       "NZL        21        86196.952381   35795.098087\n",
       "POL        60        64081.483333   42061.947198\n",
       "PRT        21        49248.666667   32333.119047\n",
       "SWE        35       102438.971429  163351.435846\n",
       "USA       687       179245.924309  357064.100561"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is how we would cull, not awful but also not best thing in the world\n",
    "grouped = grouped[grouped[(\"count\", \"sum\")] > cull_factor]\n",
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785a3cf5-b9d0-4ef7-b2f4-99475925e647",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
